{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experience_replay.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNfhWbe7X/Em8VGsS3jW6Hj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"W2A5cLpM5c_n"},"source":["import numpy as np\r\n","from collections import namedtuple, deque"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElMhbk395h3z"},"source":["Step = namedtuple('Step', ['state', 'action', 'reward', 'done'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZv0Fe4l5h6y"},"source":["class NStepProgress:\r\n","    \r\n","    def __init__(self, env, ai, n_step):\r\n","        self.ai = ai\r\n","        self.rewards = []\r\n","        self.env = env\r\n","        self.n_step = n_step\r\n","    \r\n","    def __iter__(self):\r\n","        state = self.env.reset()\r\n","        history = deque()\r\n","        reward = 0.0\r\n","        while True:\r\n","            action = self.ai(np.array([state]))[0][0]\r\n","            next_state, r, is_done, _ = self.env.step(action)\r\n","            reward += r\r\n","            history.append(Step(state = state, action = action, reward = r, done = is_done))\r\n","            while len(history) > self.n_step + 1:\r\n","                history.popleft()\r\n","            if len(history) == self.n_step + 1:\r\n","                yield tuple(history)\r\n","            state = next_state\r\n","            if is_done:\r\n","                if len(history) > self.n_step + 1:\r\n","                    history.popleft()\r\n","                while len(history) >= 1:\r\n","                    yield tuple(history)\r\n","                    history.popleft()\r\n","                self.rewards.append(reward)\r\n","                reward = 0.0\r\n","                state = self.env.reset()\r\n","                history.clear()\r\n","    \r\n","    def rewards_steps(self):\r\n","        rewards_steps = self.rewards\r\n","        self.rewards = []\r\n","        return rewards_steps"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ohdzhd555iAi"},"source":["class ReplayMemory:\r\n","    \r\n","    def __init__(self, n_steps, capacity = 10000):\r\n","        self.capacity = capacity\r\n","        self.n_steps = n_steps\r\n","        self.n_steps_iter = iter(n_steps)\r\n","        self.buffer = deque()\r\n","\r\n","    def sample_batch(self, batch_size): # creates an iterator that returns random batches\r\n","        ofs = 0\r\n","        vals = list(self.buffer)\r\n","        np.random.shuffle(vals)\r\n","        while (ofs+1)*batch_size <= len(self.buffer):\r\n","            yield vals[ofs*batch_size:(ofs+1)*batch_size]\r\n","            ofs += 1\r\n","\r\n","    def run_steps(self, samples):\r\n","        while samples > 0:\r\n","            entry = next(self.n_steps_iter) # 10 consecutive steps\r\n","            self.buffer.append(entry) # we put 200 for the current episode\r\n","            samples -= 1\r\n","        while len(self.buffer) > self.capacity: # we accumulate no more than the capacity (10000)\r\n","            self.buffer.popleft()"],"execution_count":null,"outputs":[]}]}