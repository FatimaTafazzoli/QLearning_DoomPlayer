{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNBP3WsTR1D05nuB0VMVdrj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"7kjAb9CJyGtm"},"source":["import numpy as np\r\n","from scipy.misc import imresize\r\n","from gym.core import ObservationWrapper\r\n","from gym.spaces.box import Box"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5aduzMSMySfx"},"source":["class PreprocessImage(ObservationWrapper):\r\n","    \r\n","    def __init__(self, env, height = 64, width = 64, grayscale = True, crop = lambda img: img):\r\n","        super(PreprocessImage, self).__init__(env)\r\n","        self.img_size = (height, width)\r\n","        self.grayscale = grayscale\r\n","        self.crop = crop\r\n","        n_colors = 1 if self.grayscale else 3\r\n","        self.observation_space = Box(0.0, 1.0, [n_colors, height, width])\r\n","\r\n","    def observation(self, img):\r\n","        img = self.crop(img)\r\n","        img = imresize(img, self.img_size)\r\n","        if self.grayscale:\r\n","            img = img.mean(-1, keepdims = True)\r\n","        img = np.transpose(img, (2, 0, 1))\r\n","        img = img.astype('float32') / 255.\r\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7t-WuvYByVRA"},"source":[""],"execution_count":null,"outputs":[]}]}